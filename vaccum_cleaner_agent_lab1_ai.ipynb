{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg0+NjD/YcDQrEs2kfC/JT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proap900/AI_LAB/blob/main/vaccum_cleaner_agent_lab1_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AIA0HnfbUmbm"
      },
      "outputs": [],
      "source": [
        "# Required Libraries\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from collections import deque\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Grid Configuration\n",
        "GRID_SIZE = 10       # 10x10 environment\n",
        "DIRTY = 1            # Cell with dirt\n",
        "CLEAN = 0            # Cell is clean\n",
        "\n",
        "# Seed for reproducibility (optional)\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        # Initialize random dirt in grid\n",
        "        self.grid = [[random.choice([DIRTY, CLEAN]) for _ in range(GRID_SIZE)] for _ in range(GRID_SIZE)]\n",
        "        # Agent's initial random position\n",
        "        self.agent_pos = (random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1))\n",
        "\n",
        "        # Performance tracking\n",
        "        self.steps_taken = 0\n",
        "        self.cells_cleaned = 0\n",
        "        self.visited_cells = set()\n",
        "        self.revisit_count = 0\n",
        "\n",
        "    def get_state(self, x, y):\n",
        "        return self.grid[y][x]\n",
        "\n",
        "    def clean(self, x, y):\n",
        "        if self.grid[y][x] == DIRTY:\n",
        "            self.grid[y][x] = CLEAN\n",
        "            self.cells_cleaned += 1\n",
        "\n",
        "    def is_clean(self):\n",
        "        # Return True if no dirt left\n",
        "        return all(cell == CLEAN for row in self.grid for cell in row)\n",
        "\n",
        "    def move_agent(self, x, y):\n",
        "        if (x, y) in self.visited_cells:\n",
        "            self.revisit_count += 1\n",
        "        else:\n",
        "            self.visited_cells.add((x, y))\n",
        "        self.agent_pos = (x, y)\n",
        "        self.steps_taken += 1\n",
        "\n",
        "    def get_neighbors(self, x, y):\n",
        "        # 8 directions around agent\n",
        "        directions = [(-1, -1), (0, -1), (1, -1),\n",
        "                      (-1, 0),           (1, 0),\n",
        "                      (-1, 1),  (0, 1),  (1, 1)]\n",
        "        neighbors = {}\n",
        "        for dx, dy in directions:\n",
        "            nx, ny = x + dx, y + dy\n",
        "            if 0 <= nx < GRID_SIZE and 0 <= ny < GRID_SIZE:\n",
        "                neighbors[(nx, ny)] = self.grid[ny][nx]\n",
        "        return neighbors\n"
      ],
      "metadata": {
        "id": "rV_jx0IBaFDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Agents\n",
        "class ReflexAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    def step(self):\n",
        "        x, y = self.env.agent_pos\n",
        "\n",
        "        # Clean current cell if dirty\n",
        "        if self.env.get_state(x, y) == DIRTY:\n",
        "            self.env.clean(x, y)\n",
        "            return\n",
        "\n",
        "        # Move to any neighboring dirty cell if found\n",
        "        neighbors = self.env.get_neighbors(x, y)\n",
        "        for (nx, ny), state in neighbors.items():\n",
        "            if state == DIRTY:\n",
        "                self.env.move_agent(nx, ny)\n",
        "                return\n",
        "\n",
        "        # Otherwise move randomly to any neighbor\n",
        "        if neighbors:\n",
        "            self.env.move_agent(*random.choice(list(neighbors.keys())))\n",
        "\n",
        "class GoalBasedAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    def bfs_nearest_dirt(self, start):\n",
        "        # BFS to find nearest dirty cell\n",
        "        queue = deque([start])\n",
        "        visited = set([start])\n",
        "        parent = {start: None}\n",
        "\n",
        "        while queue:\n",
        "            current = queue.popleft()\n",
        "            if self.env.get_state(*current) == DIRTY:\n",
        "                # Reconstruct path back to start\n",
        "                path = []\n",
        "                while current != start:\n",
        "                    path.append(current)\n",
        "                    current = parent[current]\n",
        "                path.reverse()\n",
        "                return path  # Return path to nearest dirt\n",
        "\n",
        "            for neighbor in self.env.get_neighbors(*current):\n",
        "                if neighbor not in visited:\n",
        "                    visited.add(neighbor)\n",
        "                    parent[neighbor] = current\n",
        "                    queue.append(neighbor)\n",
        "        return []  # No dirt found\n",
        "\n",
        "    def step(self):\n",
        "        x, y = self.env.agent_pos\n",
        "\n",
        "        # Clean if dirty\n",
        "        if self.env.get_state(x, y) == DIRTY:\n",
        "            self.env.clean(x, y)\n",
        "            return\n",
        "\n",
        "        # Find nearest dirty cell path\n",
        "        path = self.bfs_nearest_dirt((x, y))\n",
        "\n",
        "        # Move one step toward nearest dirt if exists\n",
        "        if path:\n",
        "            next_step = path[0]\n",
        "            self.env.move_agent(*next_step)\n",
        "        else:\n",
        "            # No dirt found: random neighbor move to explore\n",
        "            neighbors = self.env.get_neighbors(x, y)\n",
        "            if neighbors:\n",
        "                self.env.move_agent(*random.choice(list(neighbors.keys())))\n",
        "\n",
        "class UtilityAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.visit_freq = [[0 for _ in range(GRID_SIZE)] for _ in range(GRID_SIZE)]\n",
        "\n",
        "    def bfs_toward_dirt(self, start):\n",
        "        queue = deque([start])\n",
        "        visited = set([start])\n",
        "        parent = {start: None}\n",
        "\n",
        "        while queue:\n",
        "            current = queue.popleft()\n",
        "            if self.env.get_state(*current) == DIRTY:\n",
        "                # Reconstruct path to dirty cell\n",
        "                path = []\n",
        "                while current != start:\n",
        "                    path.append(current)\n",
        "                    current = parent[current]\n",
        "                path.reverse()\n",
        "                return path\n",
        "            for neighbor in self.env.get_neighbors(*current):\n",
        "                if neighbor not in visited:\n",
        "                    visited.add(neighbor)\n",
        "                    parent[neighbor] = current\n",
        "                    queue.append(neighbor)\n",
        "        return []\n",
        "\n",
        "    def step(self):\n",
        "        x, y = self.env.agent_pos\n",
        "        self.visit_freq[y][x] += 1\n",
        "\n",
        "        if self.env.get_state(x, y) == DIRTY:\n",
        "            self.env.clean(x, y)\n",
        "            return\n",
        "\n",
        "        neighbors = self.env.get_neighbors(x, y)\n",
        "        best_pos = None\n",
        "        best_utility = -float('inf')\n",
        "\n",
        "        for (nx, ny), state in neighbors.items():\n",
        "            utility = 0\n",
        "            if state == DIRTY:\n",
        "                utility += 10\n",
        "            elif (nx, ny) not in self.env.visited_cells:\n",
        "                utility += 2  # reward exploring\n",
        "            # penalize frequently visited cells\n",
        "            utility -= self.visit_freq[ny][nx] * 0.5\n",
        "            if utility > best_utility:\n",
        "                best_utility = utility\n",
        "                best_pos = (nx, ny)\n",
        "\n",
        "        if best_pos and best_utility > 0:\n",
        "            self.env.move_agent(*best_pos)\n",
        "        else:\n",
        "            # If all neighbors have bad utility, use BFS to head toward far dirt\n",
        "            path = self.bfs_toward_dirt((x, y))\n",
        "            if path:\n",
        "                next_step = path[0]\n",
        "                self.env.move_agent(*next_step)\n",
        "            else:\n",
        "                # fallback: move randomly\n",
        "                if neighbors:\n",
        "                    self.env.move_agent(*random.choice(list(neighbors.keys())))\n",
        "\n"
      ],
      "metadata": {
        "id": "Hd8jM29VZ8Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization\n",
        "def draw_environment(env):\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    mat = np.zeros((GRID_SIZE, GRID_SIZE, 3))\n",
        "\n",
        "    for y in range(GRID_SIZE):\n",
        "        for x in range(GRID_SIZE):\n",
        "            if env.get_state(x, y) == DIRTY:\n",
        "                mat[y][x] = [0.6, 0.4, 0.2]  # Brown dirt\n",
        "            else:\n",
        "                mat[y][x] = [1.0, 1.0, 1.0]  # White clean\n",
        "\n",
        "    ax.imshow(mat, interpolation='nearest')\n",
        "\n",
        "    # Draw agent as orange circle\n",
        "    x, y = env.agent_pos\n",
        "    ax.add_patch(plt.Circle((x, y), 0.3, color='orange'))\n",
        "\n",
        "    # Highlight neighbors with blue square border\n",
        "    for nx, ny in env.get_neighbors(x, y):\n",
        "        ax.add_patch(plt.Rectangle((nx - 0.5, ny - 0.5), 1, 1,\n",
        "                                   edgecolor='blue', fill=False, linewidth=2))\n",
        "\n",
        "    ax.set_xticks(np.arange(-0.5, GRID_SIZE, 1))\n",
        "    ax.set_yticks(np.arange(-0.5, GRID_SIZE, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.grid(True, color='black')\n",
        "    plt.show()\n",
        "\n",
        "def run_gui(agent_type=\"Utility\"):\n",
        "    env = Environment()\n",
        "\n",
        "    # Initialize agent\n",
        "    if agent_type == \"Reflex\":\n",
        "        agent = ReflexAgent(env)\n",
        "    elif agent_type == \"GoalBased\":\n",
        "        agent = GoalBasedAgent(env)\n",
        "    else:\n",
        "        agent = UtilityAgent(env)\n",
        "\n",
        "    # Setup UI\n",
        "    button = widgets.Button(description=f\"Step {agent_type} Agent\")\n",
        "    output = widgets.Output(layout={'border': '1px solid black', 'padding': '10px'})\n",
        "\n",
        "    def on_click(b):\n",
        "        with output:\n",
        "            clear_output(wait=True)\n",
        "            if not env.is_clean():\n",
        "                agent.step()\n",
        "            draw_environment(env)\n",
        "            print(f\"ü§ñ Agent Type: {agent_type}\")\n",
        "            print(f\"üö∂ Steps Taken: {env.steps_taken}\")\n",
        "            print(f\"üßπ Cells Cleaned: {env.cells_cleaned}\")\n",
        "            print(f\"üîÅ Revisited Cells: {env.revisit_count}\")\n",
        "            if env.is_clean():\n",
        "                print(\"‚úÖ Cleaning complete!\")\n",
        "\n",
        "    # Bind the click event\n",
        "    button.on_click(on_click)\n",
        "\n",
        "    # Display layout: button on top\n",
        "    ui = widgets.VBox([button, output])\n",
        "    display(ui)\n",
        "\n",
        "    # Initial visualization\n",
        "    draw_environment(env)\n",
        "\n",
        "\n",
        "# To run simulation, change agent_type: \"Reflex\", \"GoalBased\", or \"Utility\"\n",
        "run_gui(agent_type=\"Utility\")\n"
      ],
      "metadata": {
        "id": "QWX3ZfyNab60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performance summary\n",
        "def run_full_sim(agent_type):\n",
        "    env = Environment()\n",
        "    if agent_type == \"Reflex\":\n",
        "        agent = ReflexAgent(env)\n",
        "    elif agent_type == \"GoalBased\":\n",
        "        agent = GoalBasedAgent(env)\n",
        "    else:\n",
        "        agent = UtilityAgent(env)\n",
        "\n",
        "    # Run until clean or max steps to avoid infinite loops\n",
        "    max_steps = 1000\n",
        "    while not env.is_clean() and env.steps_taken < max_steps:\n",
        "        agent.step()\n",
        "\n",
        "    return {\n",
        "        \"Agent\": agent_type,\n",
        "        \"Steps Taken\": env.steps_taken,\n",
        "        \"Cells Cleaned\": env.cells_cleaned,\n",
        "        \"Revisited Cells\": env.revisit_count\n",
        "    }\n",
        "\n",
        "# Run for all agents\n",
        "results = []\n",
        "for a_type in [\"Reflex\", \"GoalBased\", \"Utility\"]:\n",
        "    results.append(run_full_sim(a_type))\n",
        "\n",
        "# Plot results\n",
        "labels = [r[\"Agent\"] for r in results]\n",
        "steps = [r[\"Steps Taken\"] for r in results]\n",
        "cleaned = [r[\"Cells Cleaned\"] for r in results]\n",
        "revisited = [r[\"Revisited Cells\"] for r in results]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "rects1 = ax.bar(x - width, steps, width, label='Steps Taken')\n",
        "rects2 = ax.bar(x, cleaned, width, label='Cells Cleaned')\n",
        "rects3 = ax.bar(x + width, revisited, width, label='Revisited Cells')\n",
        "\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Vacuum Agent Performance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "for rect in rects1 + rects2 + rects3:\n",
        "    height = rect.get_height()\n",
        "    ax.annotate('{}'.format(height),\n",
        "                xy=(rect.get_x() + rect.get_width()/2, height),\n",
        "                xytext=(0,3),  # 3 points vertical offset\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7yHwrciAg9If"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}